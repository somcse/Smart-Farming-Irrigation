{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506f756-9536-411a-b161-3e1c9a733d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of clusters and clustering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"ds1_balanced.csv\")\n",
    "\n",
    "# Fix column names (strip spaces and lowercase for consistency)\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"Column names in dataset:\", df.columns.tolist())  # Print actual column names\n",
    "\n",
    "# Define expected attributes\n",
    "expected_attributes = ['soil_moisture', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "\n",
    "# Map actual columns (case-insensitive handling)\n",
    "actual_columns = {col.lower(): col for col in df.columns}  \n",
    "attributes = [actual_columns[attr.lower()] if attr.lower() in actual_columns else None for attr in expected_attributes]\n",
    "\n",
    "# Remove missing attributes\n",
    "attributes = [attr for attr in attributes if attr is not None]\n",
    "print(\"Processing attributes:\", attributes)  # Ensure all attributes are included\n",
    "\n",
    "if not attributes:\n",
    "    raise ValueError(\"None of the specified attributes were found in the dataset!\")\n",
    "\n",
    "optimal_clusters_dict = {}  # Store results\n",
    "\n",
    "# Loop through attributes\n",
    "for attribute in attributes:\n",
    "    print(f\"\\nProcessing: {attribute}\")\n",
    "\n",
    "    data = df[[attribute]].values  \n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "    max_clusters = 10\n",
    "    fpc_values, pe_values = [], []\n",
    "    cluster_range = range(2, max_clusters + 1)\n",
    "\n",
    "    for n_clusters in cluster_range:\n",
    "        # Apply Gaussian Mixture Model (GMM)\n",
    "        gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "        gmm.fit(data_scaled)\n",
    "        \n",
    "        # Get the fuzzy membership (responsibilities)\n",
    "        responsibilities = gmm.predict_proba(data_scaled)\n",
    "        \n",
    "        # Calculate the FPC (Fuzzy Partition Coefficient)\n",
    "        fpc = np.sum(responsibilities**2) / len(data_scaled)\n",
    "        fpc_values.append(fpc)  # Store FPC value\n",
    "        \n",
    "        # Calculate the Partition Entropy (PE)\n",
    "        pe = -np.sum(responsibilities * np.log2(responsibilities + 1e-10)) / len(data_scaled)\n",
    "        pe_values.append(pe)  # Store PE value\n",
    "\n",
    "    # Normalize FPC & PE\n",
    "    fpc_norm = (fpc_values - np.min(fpc_values)) / (np.max(fpc_values) - np.min(fpc_values))\n",
    "    pe_norm = (pe_values - np.min(pe_values)) / (np.max(pe_values) - np.min(pe_values))\n",
    "\n",
    "    # Find intersection\n",
    "    intersection_point = None\n",
    "    for i in range(len(cluster_range) - 1):\n",
    "        if (fpc_norm[i] - pe_norm[i]) * (fpc_norm[i + 1] - pe_norm[i + 1]) < 0:\n",
    "            x1, x2 = cluster_range[i], cluster_range[i + 1]\n",
    "            y1_fpc, y2_fpc = fpc_norm[i], fpc_norm[i + 1]\n",
    "            y1_pe, y2_pe = pe_norm[i], pe_norm[i + 1]\n",
    "\n",
    "            slope_fpc = (y2_fpc - y1_fpc) / (x2 - x1)\n",
    "            slope_pe = (y2_pe - y1_pe) / (x2 - x1)\n",
    "            intersection_x = (y1_pe - y1_fpc + slope_fpc * x1 - slope_pe * x1) / (slope_fpc - slope_pe)\n",
    "            intersection_y = y1_fpc + slope_fpc * (intersection_x - x1)\n",
    "            intersection_point = (intersection_x, intersection_y)\n",
    "            break\n",
    "\n",
    "    # Determine optimal clusters\n",
    "    optimal_clusters = int(round(intersection_point[0])) if intersection_point else None\n",
    "    optimal_clusters_dict[attribute] = optimal_clusters\n",
    "    print(f\"Optimal clusters for {attribute}: {optimal_clusters}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(cluster_range, fpc_norm, marker='o', linestyle='-', color='b', label='FPC (Normalized)')\n",
    "    plt.plot(cluster_range, pe_norm, marker='o', linestyle='-', color='g', label='PE (Normalized)')\n",
    "    plt.title(f'FPC & PE for {attribute}')\n",
    "    plt.xlabel('Clusters')\n",
    "    plt.ylabel('Normalized Value')\n",
    "    plt.xticks(cluster_range)\n",
    "    plt.grid()\n",
    "    \n",
    "    if intersection_point:\n",
    "        plt.scatter(intersection_point[0], intersection_point[1], color='r', label=f'Intersection (k={intersection_point[0]:.2f})')\n",
    "        plt.axvline(x=optimal_clusters, color='m', linestyle=':', label=f'Optimal k={optimal_clusters}')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Run Gaussian Mixture Model (GMM) for optimal clusters\n",
    "    if optimal_clusters:\n",
    "        gmm = GaussianMixture(n_components=optimal_clusters, random_state=42)\n",
    "        gmm.fit(data_scaled)\n",
    "        cluster_centers = scaler.inverse_transform(gmm.means_)\n",
    "        print(f\"Cluster Centers for {attribute}:\\n\", cluster_centers)\n",
    "\n",
    "        cluster_membership = gmm.predict(data_scaled)\n",
    "        df[f'{attribute}_cluster'] = cluster_membership\n",
    "\n",
    "        # Print cluster analysis\n",
    "        print(f\"\\nCluster Analysis for {attribute}:\")\n",
    "        print(df.groupby(f'{attribute}_cluster')[attribute].describe())\n",
    "\n",
    "        # Visualize clusters\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(range(len(data_scaled)), data_scaled, c=cluster_membership, cmap='viridis', marker='o')\n",
    "        plt.title(f'Clustering ({attribute}, k={optimal_clusters})')\n",
    "        plt.xlabel('Data Index')\n",
    "        plt.ylabel(f'{attribute} (Scaled)')\n",
    "        plt.colorbar(label='Cluster')\n",
    "        plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nFinal Optimal Clusters:\")\n",
    "for attr, clusters in optimal_clusters_dict.items():\n",
    "    print(f\"{attr}: {clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e9b48-7103-4179-a6b5-76257de20fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
