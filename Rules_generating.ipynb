{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825847a0-abb1-459f-8e04-39e86101843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. decision tree, rule and performance\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score, accuracy_score\n",
    "\n",
    "class FuzzyDecisionTreeGini:\n",
    "    def __init__(self, max_depth=3, min_samples_split=10):  # Fixed constructor\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "        self.feature_names = ['soil_moisture_fuzzy', 'temperature_fuzzy', 'humidity_fuzzy', 'ph_fuzzy', 'rainfall_fuzzy']\n",
    "        self.label_names = ['OFF', 'ON']\n",
    "        self.used_features = set()\n",
    "    \n",
    "    def _ensure_numpy(self, data):\n",
    "        data = np.array(data, dtype=object)\n",
    "        if len(data.shape) == 1:\n",
    "            data = data.reshape(1, -1)\n",
    "        return data\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = self._ensure_numpy(X)\n",
    "        y = self._ensure_numpy(y).flatten()\n",
    "        \n",
    "        if X.shape[0] != len(self.feature_names):\n",
    "            X = X.T\n",
    "        \n",
    "        categorical_data = []\n",
    "        for i in range(X.shape[1]):\n",
    "            sample = {}\n",
    "            for j, feature in enumerate(self.feature_names):\n",
    "                sample[feature] = X[j, i]\n",
    "            categorical_data.append(sample)\n",
    "        \n",
    "        self.used_features = set()\n",
    "        self.tree = self._build_tree(categorical_data, y, depth=0)\n",
    "    \n",
    "    def _calculate_gini(self, labels):\n",
    "        if len(labels) == 0:\n",
    "            return 0\n",
    "        p = np.mean(labels)\n",
    "        return 1 - p*2 - (1-p)*2\n",
    "    \n",
    "    def _build_tree(self, data, labels, depth):\n",
    "        labels = np.array(labels, dtype=int)\n",
    "        if (depth >= self.max_depth or \n",
    "            len(data) < self.min_samples_split or \n",
    "            len(np.unique(labels)) == 1):\n",
    "            return {'prediction': np.mean(labels) > 0.5}\n",
    "        \n",
    "        best_gini = float('inf')\n",
    "        best_feature = None\n",
    "        \n",
    "        available_features = [f for f in self.feature_names if f not in self.used_features]\n",
    "        \n",
    "        for feature in available_features:\n",
    "            value_counts = defaultdict(list)\n",
    "            for i, sample in enumerate(data):\n",
    "                value = str(sample[feature])\n",
    "                value_counts[value].append(labels[i])\n",
    "            \n",
    "            weighted_gini = 0\n",
    "            for value_labels in value_counts.values():\n",
    "                p = len(value_labels) / len(labels)\n",
    "                weighted_gini += p * self._calculate_gini(value_labels)\n",
    "            \n",
    "            if weighted_gini < best_gini:\n",
    "                best_gini = weighted_gini\n",
    "                best_feature = feature\n",
    "        \n",
    "        if best_feature is None:\n",
    "            return {'prediction': np.mean(labels) > 0.5}\n",
    "        \n",
    "        self.used_features.add(best_feature)\n",
    "        tree = {'feature': best_feature, 'children': {}}\n",
    "        value_groups = defaultdict(list)\n",
    "        for i, sample in enumerate(data):\n",
    "            value = str(sample[best_feature])\n",
    "            value_groups[value].append((sample, labels[i]))\n",
    "        \n",
    "        for value, items in value_groups.items():\n",
    "            sub_data, sub_labels = zip(*items)\n",
    "            tree['children'][value] = self._build_tree(sub_data, sub_labels, depth+1)\n",
    "        \n",
    "        self.used_features.remove(best_feature)\n",
    "        return tree\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.tree is None:\n",
    "            raise ValueError(\"Model not trained yet!\")\n",
    "            \n",
    "        X = self._ensure_numpy(X)\n",
    "        if X.shape[0] != len(self.feature_names):\n",
    "            X = X.T\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(X.shape[1]):\n",
    "            sample = {}\n",
    "            for j, feature in enumerate(self.feature_names):\n",
    "                sample[feature] = X[j, i]\n",
    "            \n",
    "            node = self.tree\n",
    "            while 'children' in node:\n",
    "                feature_value = str(sample[node['feature']])\n",
    "                if feature_value in node['children']:\n",
    "                    node = node['children'][feature_value]\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            if 'prediction' in node:\n",
    "                predictions.append(node['prediction'])\n",
    "            else:\n",
    "                predictions.append(False)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def print_rules(self, node=None, path=None):\n",
    "        if node is None:\n",
    "            if self.tree is None:\n",
    "                print(\"Model not trained yet!\")\n",
    "                return\n",
    "            node = self.tree\n",
    "            path = []\n",
    "        \n",
    "        if 'prediction' in node:\n",
    "            conditions = \" AND \".join(path) if path else \"ALWAYS\"\n",
    "            print(f\"IF {conditions} THEN Pump is {'ON' if node['prediction'] else 'OFF'}\")\n",
    "            return\n",
    "        \n",
    "        for value, child in node['children'].items():\n",
    "            new_path = path + [f\"{node['feature']} is {value}\"]\n",
    "            self.print_rules(child, new_path)\n",
    "    \n",
    "    def visualize_tree(self, filename='balanced_decision_tree_gini.png'):\n",
    "        if self.tree is None:\n",
    "            print(\"Model not trained yet!\")\n",
    "            return\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        ax.axis('off')\n",
    "        plt.title(\"Fuzzy Decision Tree (Gini Index)\", pad=20, fontsize=16)\n",
    "        \n",
    "        max_depth = self._get_tree_depth(self.tree)\n",
    "        self._draw_node(ax, self.tree, x=0.5, y=0.9, width=0.4, depth=0, max_depth=max_depth)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Tree visualization saved as {filename}\")\n",
    "        plt.close()\n",
    "    \n",
    "    def _get_tree_depth(self, node):\n",
    "        if 'prediction' in node:\n",
    "            return 0\n",
    "        max_depth = 0\n",
    "        for child in node['children'].values():\n",
    "            depth = self._get_tree_depth(child)\n",
    "            if depth > max_depth:\n",
    "                max_depth = depth\n",
    "        return max_depth + 1\n",
    "    \n",
    "    def _draw_node(self, ax, node, x, y, width, depth, max_depth):\n",
    "        y_step = 0.7 / max_depth\n",
    "        \n",
    "        if 'prediction' in node:\n",
    "            color = 'lightgreen' if node['prediction'] else 'lightcoral'\n",
    "            ax.add_patch(Rectangle((x-width/2, y-0.02), width, 0.04, \n",
    "                          color=color, ec='black', lw=1))\n",
    "            ax.text(x, y, f\"Pump: {'ON' if node['prediction'] else 'OFF'}\",\n",
    "                   ha='center', va='center', fontsize=10, bbox=dict(facecolor=color, alpha=0.7))\n",
    "        else:\n",
    "            ax.add_patch(Rectangle((x-width/2, y-0.02), width, 0.04,\n",
    "                          color='lightblue', ec='black', lw=1))\n",
    "            ax.text(x, y, f\"{node['feature']}?\", \n",
    "                   ha='center', va='center', fontsize=10, bbox=dict(facecolor='lightblue', alpha=0.7))\n",
    "            \n",
    "            num_children = len(node['children'])\n",
    "            if num_children == 0:\n",
    "                return\n",
    "                \n",
    "            child_width = width / num_children\n",
    "            x_pos = x - width/2 + child_width/2\n",
    "            \n",
    "            for i, (value, child) in enumerate(node['children'].items()):\n",
    "                ax.plot([x, x_pos], [y-0.02, y-y_step+0.02], 'k-', lw=1)\n",
    "                ax.text((x+x_pos)/2, y-y_step/2, value, \n",
    "                       ha='center', va='center', fontsize=9, rotation=45)\n",
    "                self._draw_node(ax, child, x_pos, y-y_step, \n",
    "                              child_width*0.9, depth+1, max_depth)\n",
    "                x_pos += child_width\n",
    "\n",
    "    def evaluate_performance(self, y_true, y_pred, dataset_name=\"Dataset\"):\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"\\nPerformance on {dataset_name}:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Accuracy          : {accuracy:.4f}\")\n",
    "        print(f\"Precision         : {precision:.4f}\")\n",
    "        print(f\"Recall            : {recall:.4f}\")\n",
    "        print(f\"F1-Score          : {f1:.4f}\")\n",
    "        print(f\"Balanced Accuracy : {balanced_acc:.4f}\")\n",
    "        \n",
    "\n",
    "def load_fuzzy_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    fuzzy_columns = ['soil_moisture_fuzzy', 'temperature_fuzzy', 'humidity_fuzzy', \n",
    "                    'ph_fuzzy', 'rainfall_fuzzy']\n",
    "    \n",
    "    for col in fuzzy_columns:\n",
    "        data[col] = data[col].str.lower().str.strip()\n",
    "    \n",
    "    X = data[fuzzy_columns].values.T\n",
    "    y = data['Pump Data'].apply(lambda x: 1 if x == 'ON' else 0).values\n",
    "    return X, y\n",
    "\n",
    "# Fixed __name__ check\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Fuzzy Decision Tree with Gini Index Implementation\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        X, y = load_fuzzy_data(\"balanced_fuzzified_dataset.csv\")\n",
    "        print(f\"Loaded dataset with {X.shape[1]} samples\")\n",
    "        \n",
    "        split_idx = int(0.8 * X.shape[1])\n",
    "        X_train, X_test = X[:, :split_idx], X[:, split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        print(\"\\nTraining Fuzzy Decision Tree using Gini Index...\")\n",
    "        fdt = FuzzyDecisionTreeGini(max_depth=4, min_samples_split=5)\n",
    "        fdt.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"\\nGenerated Decision Rules:\")\n",
    "        print(\"=\"*40)\n",
    "        fdt.print_rules()\n",
    "        \n",
    "        print(\"\\nGenerating tree visualization...\")\n",
    "        fdt.visualize_tree()\n",
    "        \n",
    "        train_pred = fdt.predict(X_train)\n",
    "        test_pred = fdt.predict(X_test)\n",
    "\n",
    "        fdt.evaluate_performance(y_train, train_pred, dataset_name=\"Training Set\")\n",
    "        fdt.evaluate_performance(y_test, test_pred, dataset_name=\"Test Set\")\n",
    "        \n",
    "        print(\"\\nExample Test Predictions:\")\n",
    "        print(\"=\"*40)\n",
    "        for i in range(min(5, X_test.shape[1])):\n",
    "            print(f\"Sample {i+1}:\")\n",
    "            for j, feature in enumerate(fdt.feature_names):\n",
    "                print(f\"  {feature}: {X_test[j, i]}\")\n",
    "            print(f\"  Actual: {'ON' if y_test[i] else 'OFF'}\")\n",
    "            print(f\"  Predicted: {'ON' if test_pred[i] else 'OFF'}\\n\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'balanced_fuzzified_dataset.csv' not found in current directory\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1907ab3b-6027-4414-b656-7fb1165a8bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
